{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be415c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# import EarlyStopping\n",
    "from pytorchtools2 import EarlyStopping\n",
    "from  torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12daae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./IDRID_Croped/\" #---84%\n",
    "#data_dir = \"./IDRID_Croped_Augmented/\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'\n",
    "num_classes = 3 #len(class_names)\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 25\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 25\n",
    "lr=0.01\n",
    "step_size=2000\n",
    "#Early stopping patience\n",
    "patience = 10\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec827862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "    \n",
    "    train_batches = len(dataloaders[TRAIN])\n",
    "    val_batches = len(dataloaders[VAL])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "        \n",
    "        for i, data in enumerate(dataloaders[TRAIN]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "                \n",
    "            # Use half training dataset\n",
    "            if i >= train_batches / 2:\n",
    "                break\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "#                 inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()  \n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            \n",
    "             #loss_train += loss.data[0]------------------\n",
    "            loss_train += loss.item()\n",
    "            acc_train += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "#             torch.cuda.empty_cache()\n",
    "        \n",
    "        print()\n",
    "        # * 2 as we only used half of the dataset\n",
    "        avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
    "        avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
    "        \n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "            \n",
    "        for i, data in enumerate(dataloaders[VAL]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "#                 inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_val += loss.item()\n",
    "            acc_val += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "#             torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "        avg_acc_val = acc_val / dataset_sizes[VAL]\n",
    "        \n",
    "        print()\n",
    "        print(\"Epoch {} result: \".format(epoch))\n",
    "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "        \n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c208d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        # Data augmentation is a good practice for the train set\n",
    "        # Here, we randomly crop the image to 224x224 and\n",
    "        # randomly flip it horizontally. \n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), \n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=batch_size,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n",
    "\n",
    "for x in [TRAIN, VAL, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)\n",
    "# ------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b950dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs, classes):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "show_databatch(inputs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee862748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(vgg, num_images=6):\n",
    "    was_training = vgg.training\n",
    "    \n",
    "    # Set model for evaluation\n",
    "    vgg.train(False)\n",
    "    vgg.eval() \n",
    "    \n",
    "    images_so_far = 0\n",
    "\n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        inputs, labels = data\n",
    "        size = inputs.size()[0]\n",
    "        \n",
    "        if use_gpu:\n",
    "#             inputs, labels = Variable(inputs.device(), volatile=True), Variable(labels.device(), volatile=True)\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        \n",
    "        outputs = vgg(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n",
    "        \n",
    "        print(\"Ground truth:\")\n",
    "        show_databatch(inputs.data.cpu(), labels.data.cpu())\n",
    "        print(\"Prediction:\")\n",
    "        show_databatch(inputs.data.cpu(), predicted_labels)\n",
    "        \n",
    "        del inputs, labels, outputs, preds, predicted_labels\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "        images_so_far += size\n",
    "        if images_so_far >= num_images:\n",
    "            break\n",
    "        \n",
    "    vgg.train(mode=was_training) # Revert model back to original training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64fbc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(vgg, criterion):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    test_batches = len(dataloaders[TEST])\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "        inputs, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "#             inputs, labels = Variable(inputs.to(device), volatile=True), Variable(labels.to(device), volatile=True)\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "\n",
    "        outputs = vgg(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss_test += loss.item()\n",
    "        acc_test += torch.sum(preds == labels.data)\n",
    "\n",
    "        del inputs, labels, outputs, preds\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_loss = loss_test / dataset_sizes[TEST]\n",
    "    avg_acc = acc_test / dataset_sizes[TEST]\n",
    "    \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d3b4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18 ,Resnet34\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "#         model_ft = torchvision.models.quantization.resnet18(pretrained=True, quantize=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "       \n",
    "        \n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"EfficientNet\":\n",
    "        \"\"\" EfficientDet-d1,EfficientNet-b1 \n",
    "        \"\"\"\n",
    "        model_ft = models.efficientnet_b1(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        #num_ftrs = model_ft.classifier.in_features\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "\n",
    "    elif model_name == \"mobilenet\":\n",
    "       \n",
    "        \"\"\" mobilenet ,mobilenet\n",
    "        \"\"\"\n",
    "        model_ft = torchvision.models.quantization.mobilenet_v2(pretrained=True, quantize=True)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        #num_ftrs = model_ft.classifier.in_features\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "        \n",
    "    \n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn ,VGG16_bn\n",
    "        \"\"\"\n",
    "                \n",
    "#         model_ft = torchvision.models.quantization.vgg11_bn(pretrained=True, quantize=True)\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "         \n",
    "        print(model_ft.classifier[6].out_features) # 1000 --------------------------\n",
    "        # Freeze training for all layers\n",
    "        for param in model_ft.features.parameters():\n",
    "             param.require_grad = False\n",
    "        \n",
    "        # Newly created modules have require_grad=True by default\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        features = list(model_ft.classifier.children())[:-1] # Remove last layer\n",
    "        features.extend([nn.Linear(num_ftrs, len(class_names))]) # Add our layer with 4 outputs\n",
    "        model_ft.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "        print(model_ft)\n",
    "        \n",
    "    \n",
    "    \n",
    "         #set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        #num_ftrs = model_ft.classifier[6].in_features\n",
    "        #model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet,Squeezenet_1\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet,121,161\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet161(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "\n",
    "# # Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "# model_name = \"vgg\"\n",
    "\n",
    "# # Initialize the model for this run\n",
    "# # #/////////////////////////////////////////////////////\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# # # Print the model we just instantiated\n",
    "# print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa3c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the pretrained model from pytorch\n",
    "model_ft = models.vgg16_bn()\n",
    "model_ft.load_state_dict(torch.load(\"./pretain/vgg/vgg16_bn.pth\"))\n",
    "\n",
    "# r18.load_state_dict(torch.load(PATH))  # load the saved model\n",
    "     # We now have an instance of the pretrained model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(model_ft.classifier[6].out_features) # 1000 \n",
    "\n",
    "\n",
    "# Freeze training for all layers\n",
    "for param in model_ft.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "# Newly created modules have require_grad=True by default\n",
    "num_features = model_ft.classifier[6].in_features\n",
    "features = list(model_ft.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with  outputs\n",
    "model_ft.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "\n",
    "\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb533283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to train the model for more than 2 epochs, set this to True after the first run\n",
    "resume_training = False\n",
    "\n",
    "if resume_training:  \n",
    "    print(\"Loading pretrained model..\")\n",
    "        #model_ft.load_state_dict(torch.load('./pretain/resnet50-19c8e357.pth'))\n",
    "    \n",
    "    checkpoint  = torch.load('./pretain/output/av 0.8350  best 0.8544 .pt', map_location=torch.device('cpu'))\n",
    "    model_ft = torch.nn.DataParallel(model_ft )\n",
    "    model_ft.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "    #print(\"Loaded!\")\n",
    " \n",
    "\n",
    "    #model_ft.load_state_dict(torch.load('./pretain/vgg/VGG16_v2-OCT_Retina_half_dataset.pt'))\n",
    "   \n",
    "\n",
    "    #model_ft = BertForSequenceClassification.from_pretrained(\"./pretain/vgg/VGG16_v2-OCT_Retina_half_dataset.pt\", num_labels= 3, ignore_mismatched_sizes=True)\n",
    "    \n",
    "\n",
    "   \n",
    "  \n",
    "    print(\"Loaded!\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e08131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshowxxxxxx(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "# inputs, classes = next(iter(dataloaders_dict['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4132fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the model to GPU\n",
    "#model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "            \n",
    "# Observe that all parameters are being optimized lr=0.001, test 0.01,0.0001\n",
    "#optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "#optimizer_ft = optim.SGD(params_to_update, lr=0.1)# \n",
    "\n",
    "# if use_gpu:\n",
    "#     model_ft.cuda() #.cuda() will move everything to the GPU side\n",
    "device = torch.device(\"cpu\")\n",
    "model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=step_size, gamma=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_modelxxxxxxxxx(vgg, criterion):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    test_batches = len(dataloaders[TEST])\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "        inputs, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "#             inputs, labels = Variable(inputs.device(), volatile=True), Variable(labels.device(), volatile=True)\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "\n",
    "        outputs = vgg(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss_test += loss.item()\n",
    "        acc_test += torch.sum(preds == labels.data)\n",
    "\n",
    "        del inputs, labels, outputs, preds\n",
    "        torch.device.empty_cache()\n",
    "        \n",
    "    avg_loss = loss_test / dataset_sizes[TEST]\n",
    "    avg_acc = acc_test / dataset_sizes[TEST]\n",
    "    \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "    print('-' * 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58944d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test before training\")\n",
    "# eval_model(model_ft, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e590d0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize_model(model_ft)\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "import torch\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "from torchvision.models.vgg import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
    "    os.remove('temp.p')\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b02b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup the loss fxn\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "#model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, \n",
    "                             #patience=patience, is_inception=(model_name==\"inception\"))\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs)\n",
    "# torch.save(model_ft.state_dict(), './pretain/output/VGG16_v2-DME.pt')\n",
    "\n",
    "\n",
    "model_int8 = torch.quantization.quantize_dynamic(model_ft,  # the original model\n",
    "                                                  {nn.LSTM,nn.Linear},  # a set of layers to dynamically quantize\n",
    "                                                  dtype=torch.qint8)\n",
    "    \n",
    "f=print_size_of_model(model_ft,\"model_fp32\")\n",
    "q=print_size_of_model(model_int8,\"model_int8\")\n",
    "print(\"{0:.2f} times smaller\".format(f/q))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scripted_module = torch.jit.script(model_int8)\n",
    "optimized_scripted_module = optimize_for_mobile(scripted_module)\n",
    "\n",
    "torch.jit.save(optimized_scripted_module, \"mobilemodel.pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model_ft, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft, num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(vgg, num_images):\n",
    "    was_training = vgg.training\n",
    "    \n",
    "    # Set model for evaluation\n",
    "    vgg.train(False)\n",
    "    vgg.eval() \n",
    "    \n",
    "    images_so_far = 0\n",
    "  \n",
    "        \n",
    "        \n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        inputs, labels = data\n",
    "        size = inputs.size()[0]\n",
    "        \n",
    "        if use_gpu:\n",
    "#             inputs, labels = Variable(inputs.device(), volatile=True), Variable(labels.device(), volatile=True)\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        \n",
    "        outputs = vgg(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Ground truth:\")\n",
    "        show_databatch(inputs.data.cpu(), labels.data.cpu())\n",
    "        print(\"Prediction:\")\n",
    "        show_databatch(inputs.data.cpu(), predicted_labels)\n",
    "  \n",
    "        #print(metrics.confusion_matrix(labels.data.cpu(),preds.data.cpu()));    \n",
    "       \n",
    "        print(metrics.classification_report(labels.data.cpu(),preds.data.cpu(),digits=3));\n",
    "\n",
    "\n",
    "        cm1 = confusion_matrix(labels.data.cpu(),preds.data.cpu());\n",
    "        print('Confusion Matrix : \\n', cm1)\n",
    "        \n",
    "        total1=sum(sum(cm1))\n",
    "#####from confusion matrix calculate accuracy\n",
    "        accuracy1=(cm1[0,0]+cm1[1,1]+cm1[2,2])/total1\n",
    "        print ('Accuracy : ', accuracy1)\n",
    "#         format_float = \"{:.2f}\".format(accuracy1)\n",
    "#         print ('Accuracy : ', format_float)\n",
    "\n",
    "        print('Specificity: -macro: ', specificity_score(labels.data.cpu(),preds.data.cpu(), average='macro'))\n",
    "        print('Sensitivity: -macro : ', sensitivity_score(labels.data.cpu(),preds.data.cpu(), average='macro'))\n",
    "        print('precision_score: -macro', precision_score(labels.data.cpu(),preds.data.cpu(), average='macro'))\n",
    "        print('f1_score: -macro', f1_score(labels.data.cpu(),preds.data.cpu(), average='macro'))\n",
    "        \n",
    "        print('Specificity: -weighted: ', specificity_score(labels.data.cpu(),preds.data.cpu(), average='weighted'))\n",
    "        print('Sensitivity: -weighted : ', sensitivity_score(labels.data.cpu(),preds.data.cpu(), average='weighted'))\n",
    "        print('f1_score: -weighted', f1_score(labels.data.cpu(),preds.data.cpu(), average='weighted'))\n",
    "        print('precision_score: -weighted', precision_score(labels.data.cpu(),preds.data.cpu(), average='weighted'))\n",
    "        \n",
    "        print('matthews_corrcoef: ', matthews_corrcoef(labels.data.cpu(),preds.data.cpu()))\n",
    "        print('accuracy_score: ', accuracy_score(labels.data.cpu(),preds.data.cpu(), normalize=True))\n",
    "\n",
    "        \n",
    "        \n",
    "        cm = metrics.confusion_matrix(labels.data.cpu(),preds.data.cpu())\n",
    "        plot_confusion_matrix(cm, classes=['True', 'False'])\n",
    "\n",
    "        del inputs, labels, outputs, preds, predicted_labels\n",
    "        \n",
    "        \n",
    "        \n",
    "#         torch.device.empty_cache()\n",
    "        \n",
    "        images_so_far += size\n",
    "        if images_so_far >= num_images:\n",
    "            break\n",
    "        \n",
    "    vgg.train(mode=was_training) # Revert model back to original training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82617c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import sklearn.metrics as confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from imblearn.metrics import specificity_score\n",
    "from imblearn.metrics import sensitivity_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "confusionMatrix(model_ft, num_images=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a580e",
   "metadata": {},
   "source": [
    "testing_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "testing_generator = testing_datagen.flow_from_directory(\n",
    "testing_dir,\n",
    "target_size=(200, 200),\n",
    "batch_size=batch_size,\n",
    "shuffle=False,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42eade1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3236d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
